{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan-mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6NX08GRfRli",
        "colab_type": "text"
      },
      "source": [
        "#GAN - MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzajUrQPpHKA",
        "colab_type": "text"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0xXTO7ijGHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdLFetGwpJka",
        "colab_type": "text"
      },
      "source": [
        "##Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT0Pp1UljUPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Initialize Batch Size\n",
        "batch_size = 64\n",
        "\n",
        "# Load Dataset\n",
        "train_dataset = datasets.MNIST(root='data', train=True, download =True, transform=transforms.ToTensor())\n",
        "\n",
        "# Prepare the dataloader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh0dtKrSpL81",
        "colab_type": "text"
      },
      "source": [
        "##Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouajGzj3lD-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "66a138a4-361c-460f-d43c-616135e349a2"
      },
      "source": [
        "# obtain one batch of training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "images = images.numpy()\n",
        "\n",
        "# get one image from the batch\n",
        "img = np.squeeze(images[0])\n",
        "\n",
        "fig = plt.figure(figsize = (3,3)) \n",
        "px = fig.add_subplot(111)\n",
        "px.imshow(img, cmap='gray')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4912408940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADFCAYAAAARxr1AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JLQbBVsfIee",
        "colab_type": "text"
      },
      "source": [
        "#GAN Model\n",
        "##Discriminator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvZKA89_gFpJ",
        "colab_type": "text"
      },
      "source": [
        "It is a linear classifier with 2 hidden layers. This network uses leaky ReLU as an activation function.\n",
        "A leaky ReLU is a normal ReLU function but it return small non-zero value for negative inputs. We use leaky ReLU so gradients can backward propagate without hinderance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-NsvpxokELz",
        "colab_type": "text"
      },
      "source": [
        "Using a BCEWithLogitsLoss which combines a Sigmoid layer and the BCELoss in one single class. This version is more numerically stable. Source: [Documentation](https://pytorch.org/docs/stable/nn.html#bcewithlogitsloss)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIXXb3PCobrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_size, hidden_dim, output_size):\n",
        "    super(Discriminator, self).__init__()\n",
        "    \n",
        "    # Layers\n",
        "    self.conv1 = nn.Linear(input_size, hidden_dim*4)    # Input Layer\n",
        "    self.conv2 = nn.Linear(hidden_dim*4, hidden_dim*2)\n",
        "    self.conv3 = nn.Linear(hidden_dim*2, hidden_dim)\n",
        "    self.conv4 = nn.Linear(hidden_dim, output_size)  # Final Layer\n",
        "    \n",
        "    # Dropout layer\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "    \n",
        "    def forward(self, x):\n",
        "      # Flatten image\n",
        "      x = x.view(-1, 28*28)\n",
        "      \n",
        "      x = F.leaky_relu(self.conv1(x), 0.2)   # (input, negative_slope)\n",
        "      x = self.dropout(x)\n",
        "      x = F.leaky_relu(self.conv2(x), 0.2)\n",
        "      x = self.dropout(x)\n",
        "      x = F.leaky_relu(self.conv3(x), 0.2)\n",
        "      x = self.dropout(x)\n",
        "     \n",
        "      # Final Layer\n",
        "      output = self.conv4(x)\n",
        "      \n",
        "      return output\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRe74OSRxRu3",
        "colab_type": "text"
      },
      "source": [
        "##Add Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atwr3f4-xVzb",
        "colab_type": "text"
      },
      "source": [
        "Works like the Discriminator but use tanh as an activation function in the output layer.\n",
        "Generator works best when tanh is scaled between -1 and 1.\n",
        "So we will have to scale our real input images to have pixel values between -1 and 1 when we train the discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Cf2_ZpmwBK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_size, hidden_dim, output_size):\n",
        "    super(Generator, self).__init__()\n",
        "    \n",
        "    # Layers\n",
        "    self.conv1 = nn.Linear(input_size, hidden_dim)    # Input Layer\n",
        "    self.conv2 = nn.Linear(hidden_dim, hidden_dim*2)\n",
        "    self.conv3 = nn.Linear(hidden_dim*2, hidden_dim*4)\n",
        "    self.conv4 = nn.Linear(hidden_dim*4, output_size)  # Final Layer\n",
        "    \n",
        "    # Dropout layer\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "    \n",
        "    def forward(self, x):\n",
        "      # Flatten image\n",
        "      x = x.view(-1, 28*28)\n",
        "      \n",
        "      x = F.leaky_relu(self.conv1(x), 0.2)   # (input, negative_slope)\n",
        "      x = self.dropout(x)\n",
        "      x = F.leaky_relu(self.conv2(x), 0.2)\n",
        "      x = self.dropout(x)\n",
        "      x = F.leaky_relu(self.conv3(x), 0.2)\n",
        "      x = self.dropout(x)\n",
        "     \n",
        "      # Final Layer\n",
        "      output = F.tanh(self.conv4(x))\n",
        "      \n",
        "      return output\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhKJivAX1Sz6",
        "colab_type": "text"
      },
      "source": [
        "##Model Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT5uVBitzZlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Discriminator Hyperarameters\n",
        "\n",
        "# Size of input image\n",
        "input_size = 784\n",
        "# Size of discriminator output\n",
        "d_output_size = 1\n",
        "# Size of last hidden layer in discriminator (layer 3)\n",
        "d_hidden_size = 32\n",
        "\n",
        "\n",
        "# Generator Hyperparamters\n",
        "\n",
        "# Size of latent vector to give to Generator (reffered as noise)\n",
        "z_size = 100\n",
        "# Size of discriminator output (generated image)\n",
        "g_output_size = 784\n",
        "# Size of first hidden layer\n",
        "g_hidden_size = 32\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tPGG7ZJ9m6e",
        "colab_type": "text"
      },
      "source": [
        "##Building Network\n",
        "Instantiating the current network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GvnM5aq9Smb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "a1201458-f7d3-4dd5-c94c-01c880c5dc9d"
      },
      "source": [
        "D = Discriminator(input_size, d_hidden_size, d_output_size)\n",
        "G = Generator(z_size, g_hidden_size, g_output_size)\n",
        "\n",
        "print(D)\n",
        "print()\n",
        "print(G)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discriminator(\n",
            "  (conv1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (conv2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (conv3): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (conv4): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (droupout): Dropout(p=0.3)\n",
            ")\n",
            "\n",
            "Generator(\n",
            "  (conv1): Linear(in_features=100, out_features=32, bias=True)\n",
            "  (conv2): Linear(in_features=32, out_features=64, bias=True)\n",
            "  (conv3): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (conv4): Linear(in_features=128, out_features=784, bias=True)\n",
            "  (droupout): Dropout(p=0.3)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc7Dhd7rxBPl",
        "colab_type": "text"
      },
      "source": [
        "##Discriminator and Generator Losses\n",
        "###Discriminator Loss\n",
        "*  Total loss = real loss + fake loss (d_loss = d_real_loss + d_fake_loss)\n",
        "*   Output = 1 for real images\n",
        "*   Output = 0 for fake images\n",
        "*   Using BCEWithLogitsLoss\n",
        "*   To generalize better we reduce the real label classification limit to 0.9 - 1.0, using *smooth* parmeter for this\n",
        "*   Generator outputs images, we want D(fake_images) = 0\n",
        "\n",
        "###Generator Loss\n",
        "*   Similar to Discriminator only flipped, D(fake_images) = 1\n",
        "*   The labels are flipped to represent that the generator is trying to fool the discriminator into thinking that the images it generates (fakes) are real!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EltQcy1e-TFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculating Loss\n",
        "def real_loss(D_out, smooth=False):\n",
        "  batch_Size = D.out.size(0)\n",
        "  # label smoothing\n",
        "  if smooth:\n",
        "    # if smooth, real_labels = 0.9\n",
        "    labels = torch.ones(batch_size) * 0.9\n",
        "  else:\n",
        "    labels = torch.ones(batch_size)\n",
        "    \n",
        "    \n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    # calculating loss\n",
        "    loss = criterion(D_out_squeeze(), labels)\n",
        "    return loss\n",
        "  \n",
        "  \n",
        "  \n",
        "def fake_loss(D_out):\n",
        "  batch_size = D_out.size(0)\n",
        "  labels = torch.zeros(batch_size)  #fake_labels = 0\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  # calculating loss\n",
        "  loss = criterion(D_out.squeeze(), labels)\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqJbeEOBL55d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTX72hbaL4-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}